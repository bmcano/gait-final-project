import ast
import hashlib
from io import BytesIO
from PIL import Image, PngImagePlugin
import openai
from flask import Flask, render_template, request
import os
from datetime import datetime
from config import DEMO_MODE, MOCK_ITINERARIES, MOCK_VIDEOS, MOCK_WEATHER_INFO
from merge_videos import merge_clips_no_transition
from dotenv import load_dotenv
import time
from runwayml import RunwayML
import base64
import requests

app = Flask(__name__)

# Configurations
# These folders contain the images generated by AI
app.config['IMAGE_FOLDER'] = 'temp/images'
app.config['VIDEO_FOLDER'] = 'temp/video'

@app.route('/')
def index():
    """
    Landing page where users enter destination and travel dates.
    """
    return render_template('index.html')

@app.route('/itineraries', methods=['POST'])
def itineraries():
    """
    Page showing multiple itinerary options in horizontal cards.
    """
    # Extract user inputs
    destination = request.form['destination']
    description = request.form['description']
    from_date = request.form['fromDate']
    to_date = request.form['toDate']
    travel_dates = from_date + " to " + to_date

    # Parse dates and calculate trip duration
    try:
        from_date_obj = datetime.strptime(from_date, "%Y-%m-%d")
        to_date_obj = datetime.strptime(to_date, "%Y-%m-%d")
        trip_duration = (to_date_obj - from_date_obj).days + 1
    except ValueError:
        return "Invalid date format. Please ensure dates are in YYYY-MM-DD format."

    # TODO: Use destination and dates to call the weather API and retrieve weather info.
    # Store the result in `weather_info` and pass it to the frontend instead of MOCK_WEATHER_INFO.
    weather_info = MOCK_WEATHER_INFO

    # TODO: Use ChatGPT to dynamically generate itineraries using destination, dates, and weather info
    # Replace MOCK_ITINERARIES with actual data from ChatGPT's response.
    itineraries = MOCK_ITINERARIES

    # TODO: Get prompt from ChatGPT to generate images
    try:
        prompt = create_must_see_attractions_prompt(destination)
        mustSeeAttractions_List = generate_must_see_attractions_list(prompt)
        # Convert to Python object
        mustSeeAttractions_List = [(mustSeeAttractions_List)][0]
        mustSeeAttractions_List = ast.literal_eval(f"[{mustSeeAttractions_List}]")

        imagePrompt_List = create_image_prompts(mustSeeAttractions_List, from_date, to_date)
        
        generated_images = generate_images_from_prompts(imagePrompt_List)
    
    except Exception as e:
        print("Error:", e)
    
    # Pass mock or generated data to the template
    return render_template(
        'itineraries.html',
        destination=destination,
        from_date=from_date,
        to_date=to_date,
        travel_dates=travel_dates,
        trip_duration=trip_duration,
        itineraries=itineraries,  # Pass generated itineraries here
        images=generated_images  # Pass generated images to the frontend
    )

@app.route('/itinerary_details', methods=['POST'])
def itinerary_details():
    """
    Page showing detailed itinerary, weather, and packing suggestions.
    """
    # TODO: Extract all selected items, and then prepare them for ChatGPT to make the itinerary with
    selected_index = request.form.get('selected_indices', '')
    selected_indices = [int(idx) for idx in selected_index.split(',') if idx.isdigit()]
    selected_itineraries = [MOCK_ITINERARIES[idx] for idx in selected_indices]

    # TODO: Use ChatGPT to dynamically generate packing suggestions based on destination, weather, and itinerary.
    packing_list = ["Sunscreen", "Comfortable shoes", "Hat", "Reusable water bottle"]

    # Grab all selected images
    selected_images = request.form.get('selected_images', '').split(',')
    if DEMO_MODE:
        merged_video = [
            {"video": MOCK_VIDEOS[0]}
        ]
    else:
        # convert all selected items into videos
        index = 0
        generated_videos = []
        for image in selected_images:
            index += 1 
            video = generate_runway_video(image, "webp", f"video{1}.mp4")
            generated_videos.append(video)
        # merge all the videos together
        merged_video = [
            {"video": merge_clips_no_transition(generated_videos)}
        ]

    # Pass mock or generated data to the template
    return render_template(
        'itinerary_details.html',
        itinerary=selected_itineraries,
        weather=MOCK_WEATHER_INFO,  # Replace with dynamic weather_info once integrated
        packing_list=packing_list,
        video=merged_video
    )

# TODO: Define the generate_image function
# Use this function to integrate an AI image generation API (e.g., DALL-E, Stable Diffusion, etc.).
# Input: Key points of interest or landmarks from the itinerary.
# Output: Save generated images in app.config['IMAGE_FOLDER'] and return their file paths.

# ---------- PROMPT GENERATION + IMAGE GENERATION ------------------

# STEP 1 : create the prompt using user's 'destination'
def create_must_see_attractions_prompt(destination):
    """
    Generate an OpenAI prompt to create 5 must-see attractions for the given destination.

    :param destination: The destination for which must-see attractions are generated.
    :return: A string OpenAI prompt to generate the attractions.
    """
    prompt = f"""
    You are a travel expert. Generate a list of 5 must-see attractions for travelers visiting {destination}.
    Each attraction should have:
    1. The name of the attraction (place_name).
    2. A brief description (description) of why it's iconic or famous.
    3. A highlight of its most notable features (features).
    Format the output as follows:
    
    ('Place Name 1', 'Brief description of the attraction', 'Key features or highlights of the place'),
    ('Place Name 2', 'Brief description of the attraction', 'Key features or highlights of the place'),
        ...
    
    Ensure that the output follows Python syntax strictly, with all strings enclosed in double quotes (`"`), and no special characters (e.g., single quotes, backslashes) causing invalid syntax. And no next-line character after the last tuple. 
    """
    return prompt

# STEP 2 : OpenAI API call to generate 5 must attractions list 
# from 'create_must_see_attractions_prompt()' function 
def generate_must_see_attractions_list(prompt):
    '''
    Using the prompt created in create_must_see_attractions_prompt(), we generate a list of must see attractions of the given destination using OpenAI API

    :param prompt: prompt
    :return: A string OpenAI prompt to generate the attractions.
    '''
    
    client = openai.OpenAI()

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {
                "role": "user",
                "content": prompt
            }
        ]
    )
    mustSeeAttractionsList = completion.choices[0].message

    return mustSeeAttractionsList.content

# STEP 3 : Using output from generate_must_see_attractions_list() function (which 
# is list of 5 must see attractions), we create image prompts for each. 
def create_image_prompts(mustSeeAttractions, fromDate, toDate):
    """
    Generate image prompts for a list of must-see attractions during the given travel dates.

    :param mustSeeAttractions: List of tuples containing (place_name, description, features).
    :param fromDate: Start date of the trip (YYYY-MM-DD).
    :param toDate: End date of the trip (YYYY-MM-DD).
    :return: List of image prompts as strings.
    """
    prompts = []
    for attraction in mustSeeAttractions:
        attraction_name, description, features = attraction
        prompt = (f"An ultra-realistic photograph of {attraction_name}, taken during a trip from {fromDate} to {toDate}. "
                  f"The scene highlights {description}, surrounded by its natural or urban environment. "
                  f"The lighting is balanced and natural, showcasing intricate details of {features}. "
                  f"The perspective is carefully chosen to emphasize the grandeur and charm of the location, "
                  f"captured with a high-quality, true-to-life photographic style.")
        prompts.append(prompt)
    return prompts

# STEP 4: Takes the list of 5 image prompts for user's destination, and using OpenAI API
# call, 5 images are generated and saved in the temp/images directory
def generate_images_from_prompts(imagePrompt_List):
    """
    Generate images using OpenAI's DALL-E model based on a list of prompts.
    :param imagePrompt_List: List of text prompts for the image generation API.
    :return: Dictionary mapping prompts to their generated image file paths.
    """
    # Configure the image storage folder. Create directory if it doesn't exist
    IMAGE_FOLDER = "temp/images"
    if not os.path.exists(IMAGE_FOLDER):
        os.makedirs(IMAGE_FOLDER)

    # Dictionary to store file paths for each prompt
    file_paths = {}

    client = openai.OpenAI()

    # Process each prompt in the list
    for prompt in imagePrompt_List:
        try:
            # Call OpenAI API for image generation
            response = client.images.generate(
                model="dall-e-3",
                quality="standard",
                size="1024x1024",  # Specify the size
                prompt=prompt,
                n=1               # Generate one image per prompt
            )

            # Extract the image URL from the response
            image_url = response.data[0].url

            # Download the image
            image_response = requests.get(image_url)
            image_response.raise_for_status()

            # Generate a short and unique filename using a hash of the prompt
            hash_object = hashlib.md5(prompt.encode())
            file_name = f"{hash_object.hexdigest()}.png"
            file_path = os.path.join(IMAGE_FOLDER, file_name)

            # Save the image to the specified folder
            image = Image.open(BytesIO(image_response.content))
            
            # --- COMMENT OUT METADATA FEATURE IF ERRORS ENCOUNTERED ---
            # Add metadata to the image
            metadata = PngImagePlugin.PngInfo()
            metadata.add_text("Prompt", prompt)  # Add the prompt as metadata
            
            image.save(file_path, "PNG", pnginfo=metadata)
            
            # Map the prompt to the file path
            file_paths[prompt] = file_path            

        except Exception as e:
            print(f"Error generating image for prompt '{prompt}': {e}")
            continue

    return file_paths

# -------------------------------------------------------------------- 

def generate_runway_video(image_path, image_tpye, output_filename):
    """
    Generate a drone-like hovering video from an input image using the Replicate API.
    :image_path: The file path to the image to convert to a video 
    :output_filename: The name of the temporary output video
    """
    if DEMO_MODE:
        print("using file in DEMO_MODE")
        return

    client = RunwayML()
    print("start")
    # Create a new image-to-video task using the "gen3a_turbo" model
    base64_image = encode_image_to_base64(image_path)
    task = client.image_to_video.create(
        model='gen3a_turbo',
        # Point this at your own image file
        prompt_image=f"data:image/{image_tpye};base64,{base64_image}",
        prompt_text='Drone-like hovering movement of the given scene',
        duration=5
    )
    task_id = task.id

    # Poll the task until it's complete
    time.sleep(10)
    task = client.tasks.retrieve(task_id)
    while task.status not in ['SUCCEEDED', 'FAILED']:
        time.sleep(10)
        task = client.tasks.retrieve(task_id)

    print('Task complete:', task)
    save_video(task.output[0], output_filename)
    return output_filename

"""
Helper functions relating to video generation 
"""
def encode_image_to_base64(image_path):
    with open(image_path, "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read()).decode("utf-8")
    return encoded_string

def save_video(video_url, output_filename):
    # Send a GET request to the video URL
    response = requests.get(video_url, stream=True)
    # Check if the request was successful
    if response.status_code == 200:
        # Open a file in binary write mode and save the video content
        with open(f"temp/video/{output_filename}.mp4", "wb") as video_file:
            for chunk in response.iter_content(chunk_size=8192):
                video_file.write(chunk)
        print("Video saved.")
    else:
        print(f"Failed to save video. Status code: {response.status_code}, Error: {response.text}")


if __name__ == '__main__':
    # Ensure required directories exist
    os.makedirs(app.config['IMAGE_FOLDER'], exist_ok=True)
    os.makedirs(app.config['VIDEO_FOLDER'], exist_ok=True)
    load_dotenv()
    app.run(debug=True)
